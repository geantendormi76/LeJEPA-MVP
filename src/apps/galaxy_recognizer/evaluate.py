import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from torch.utils.data import DataLoader
from torchvision import transforms
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import sys
import re
from pathlib import Path

# è·¯å¾„ Hack
sys.path.append(str(Path(__file__).resolve().parents[1]))

from configs.config import cfg
from src.dataset import Galaxy10Dataset
from src.modeling.encoder import LeJEPA_Encoder

def load_model(ckpt_path, device):
    """åŠ è½½æŒ‡å®š Checkpoint çš„æ¨¡å‹"""
    model = LeJEPA_Encoder(
        backbone_name=cfg.BACKBONE,
        img_size=cfg.IMG_SIZE,
        proj_dim=cfg.PROJ_DIM
    ).to(device)
    
    # å¤„ç† torch.compile å¸¦æ¥çš„å‰ç¼€é—®é¢˜
    state_dict = torch.load(ckpt_path, map_location=device)
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith("_orig_mod."):
            new_state_dict[k[10:]] = v
        else:
            new_state_dict[k] = v
            
    model.load_state_dict(new_state_dict)
    model.eval()
    return model

def extract_features(model, loader, device):
    """æå–å…¨é‡ç‰¹å¾"""
    features = []
    labels = []
    
    with torch.no_grad():
        for imgs, lbls in loader:
            imgs = imgs.to(device)
            # LeJEPA forward è¿”å› (embedding, projection)
            # æˆ‘ä»¬åªéœ€è¦ embedding (384ç»´)
            feats, _ = model(imgs)
            features.append(feats.cpu().numpy())
            labels.append(lbls.numpy())
            
    return np.concatenate(features), np.concatenate(labels)

def run_sweep():
    print("ğŸ” [AEGIS] å¯åŠ¨çº¿æ€§æ¢æµ‹æ‰«æ (Linear Probing Sweep)...")
    
    # 1. å‡†å¤‡æ•°æ® (åªåšæ ‡å‡†åŒ–ï¼Œä¸åšå¼ºå¢å¼º)
    val_transform = transforms.Compose([
        transforms.Resize(cfg.IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    dataset = Galaxy10Dataset(cfg.DATA_PATH, transform=val_transform)
    # ä½¿ç”¨å¤§ Batch åŠ é€Ÿæ¨ç†
    loader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=8)
    
    # 2. æ‰«ææ‰€æœ‰ Checkpoints
    ckpt_dir = cfg.CHECKPOINT_DIR
    # æŒ‰ Epoch æ•°å­—æ’åº (ep50, ep100...)
    ckpts = sorted(list(ckpt_dir.glob("*.pth")), key=lambda x: int(re.search(r'ep(\d+)', x.name).group(1)))
    
    if not ckpts:
        print("âŒ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼")
        return

    results = []
    
    print(f"ğŸ“‚ å‘ç° {len(ckpts)} ä¸ªæ¨¡å‹å­˜æ¡£ï¼Œå¼€å§‹é€ä¸€è¯„ä¼°...")
    print("-" * 60)
    print(f"{'Epoch':<10} | {'Accuracy':<10} | {'Status'}")
    print("-" * 60)

    best_acc = 0.0
    best_ep = 0

    for ckpt in ckpts:
        epoch_num = int(re.search(r'ep(\d+)', ckpt.name).group(1))
        
        # åŠ è½½æ¨¡å‹
        model = load_model(ckpt, cfg.DEVICE)
        
        # æå–ç‰¹å¾
        X, y = extract_features(model, loader, cfg.DEVICE)
        
        # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† (80/20)
        # æ³¨æ„ï¼šè¿™é‡Œæ˜¯åœ¨å†»ç»“çš„ç‰¹å¾ä¸Šè®­ç»ƒåˆ†ç±»å™¨
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # è®­ç»ƒé€»è¾‘å›å½’ (ç§’çº§)
        clf = LogisticRegression(max_iter=1000, C=1.0, solver='lbfgs')
        clf.fit(X_train, y_train)
        
        # è¯„ä¼°
        acc = accuracy_score(y_test, clf.predict(X_test)) * 100
        results.append((epoch_num, acc))
        
        if acc > best_acc:
            best_acc = acc
            best_ep = epoch_num
            status = "ğŸ”¥ New Best!"
        else:
            status = ""
            
        print(f"{epoch_num:<10} | {acc:.2f}%      | {status}")

    # 3. æ€»ç»“ä¸ç»˜å›¾
    print("-" * 60)
    print(f"ğŸ† æœ€ä½³æ¨¡å‹: Epoch {best_ep} (Acc: {best_acc:.2f}%)")
    
    epochs, accs = zip(*results)
    
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, accs, marker='o', linestyle='-', color='b', linewidth=2)
    plt.title(f"LeJEPA Training Progress (Linear Probe Accuracy)\nBest: {best_acc:.2f}% @ Ep{best_ep}", fontsize=14)
    plt.xlabel("Training Epochs")
    plt.ylabel("Accuracy (%)")
    plt.grid(True, alpha=0.3)
    
    # æ ‡è®°æœ€é«˜ç‚¹
    plt.plot(best_ep, best_acc, 'r*', markersize=15)
    
    save_path = "evaluation_curve.png"
    plt.savefig(save_path, dpi=300)
    print(f"ğŸ“Š è¯„ä¼°æ›²çº¿å·²ä¿å­˜è‡³: {save_path}")

if __name__ == "__main__":
    run_sweep()