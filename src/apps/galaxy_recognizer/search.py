
import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import sys
from pathlib import Path

# è·¯å¾„ Hack
sys.path.append(str(Path(__file__).resolve().parents[1]))

from configs.config import cfg
from src.dataset import Galaxy10Dataset
from src.modeling.encoder import LeJEPA_Encoder

def run_contrastive_search():
    print("ğŸ” [Demo] å¯åŠ¨å·®å¼‚åŒ–å¯¹æ¯”æœç´¢ (Contrastive Search)...")
    
    # 1. åŠ è½½æ¨¡å‹
    ckpt_dir = cfg.CHECKPOINT_DIR
    ckpts = sorted(list(ckpt_dir.glob("*.pth")))
    if not ckpts:
        print("âŒ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶")
        return
    latest_ckpt = ckpts[-1]
    print(f"ğŸ“‚ åŠ è½½æƒé‡: {latest_ckpt.name}")

    device = cfg.DEVICE
    encoder = LeJEPA_Encoder(
        backbone_name=cfg.BACKBONE,
        img_size=cfg.IMG_SIZE,
        proj_dim=cfg.PROJ_DIM
    ).to(device)
    
    state_dict = torch.load(latest_ckpt, map_location=device)
    new_state_dict = {k.replace("_orig_mod.", ""): v for k, v in state_dict.items()}
    encoder.load_state_dict(new_state_dict)
    encoder.eval()

    # 2. å‡†å¤‡æ•°æ®
    val_transform = transforms.Compose([
        transforms.Resize(cfg.IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åŸå§‹æ•°æ®é›†ç”¨äºæ˜¾ç¤º
    raw_dataset = Galaxy10Dataset(cfg.DATA_PATH, transform=None)
    # å¤„ç†åçš„æ•°æ®é›†ç”¨äºæ¨ç†
    proc_dataset = Galaxy10Dataset(cfg.DATA_PATH, transform=val_transform)
    
    # ä½¿ç”¨è¾ƒå¤§çš„ Batch åŠ é€Ÿç‰¹å¾æå–
    loader = DataLoader(proc_dataset, batch_size=256, shuffle=False, num_workers=8)

    # 3. æå–ç‰¹å¾åº“ & æ ‡ç­¾ç´¢å¼•
    print("âš¡ æ­£åœ¨æ„å»ºå…¨é‡ç‰¹å¾åº“...")
    features_db = []
    labels_db = []
    
    with torch.no_grad():
        for imgs, labels in tqdm(loader):
            imgs = imgs.to(device)
            feats, _ = encoder(imgs)
            feats = torch.nn.functional.normalize(feats, p=2, dim=1)
            features_db.append(feats.cpu())
            labels_db.append(labels)
            
    features_db = torch.cat(features_db, dim=0)
    labels_db = torch.cat(labels_db, dim=0).numpy()
    print(f"ğŸ“š ç´¢å¼•åº“æ„å»ºå®Œæˆ: {features_db.shape}")

    # 4. å®šå‘ç­›é€‰ Query (Hardcoded Selection)
    # Galaxy10 ç±»åˆ«æ˜ å°„:
    # 0: Disk, Face-on, No Spiral
    # 1: Smooth, Completely round (åœ†è›‹)
    # 2: Smooth, in-between
    # 3: Smooth, Cigar shaped
    # 4: Disk, Edge-on, Rounded Bulge (ä¾§å‘/é£ç¢Ÿ)
    # 5: Disk, Edge-on, Boxy Bulge
    # 6: Disk, Edge-on, No Bulge
    # 7: Disk, Face-on, Tight Spiral (èºæ—‹)
    # 8: Disk, Face-on, Medium Spiral
    # 9: Disk, Face-on, Loose Spiral

    # æˆ‘ä»¬é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„ä¸‰ç±»
    target_classes = {
        "Spiral (æ—‹æ¶¡çŠ¶)": 7,  # èºæ—‹
        "Smooth (åœ†è›‹çŠ¶)": 1,  # å…‰æ»‘åœ†
        "Edge-on (é£ç¢ŸçŠ¶)": 4   # ä¾§å‘
    }
    
    query_indices = []
    query_titles = []
    
    # ä»æ•°æ®åº“ä¸­ä¸ºæ¯ä¸€ç±»æ‰¾ä¸€ä¸ªä»£è¡¨
    for name, label_idx in target_classes.items():
        # æ‰¾åˆ°æ‰€æœ‰å±äºè¯¥ç±»åˆ«çš„ç´¢å¼•
        indices = np.where(labels_db == label_idx)[0]
        if len(indices) > 0:
            # éšæœºé€‰ä¸€ä¸ªä½œä¸º Query
            selected_idx = np.random.choice(indices)
            query_indices.append(selected_idx)
            query_titles.append(name)
        else:
            print(f"âš ï¸ è­¦å‘Š: æ•°æ®é›†ä¸­æœªæ‰¾åˆ°ç±»åˆ« {label_idx}")

    # 5. æ‰§è¡Œæœç´¢ä¸ç»˜å›¾
    # 3è¡Œ (Query) x 6åˆ— (1 Query + 5 Matches)
    fig, axes = plt.subplots(3, 6, figsize=(18, 10))
    plt.subplots_adjust(wspace=0.1, hspace=0.3)
    
    for row, (q_idx, q_title) in enumerate(zip(query_indices, query_titles)):
        # æœç´¢
        query_feat = features_db[q_idx].unsqueeze(0)
        sim_scores = torch.mm(query_feat, features_db.t()).squeeze(0)
        topk_scores, topk_indices = torch.topk(sim_scores, k=6)
        
        # ç»˜åˆ¶ Query (ç¬¬ä¸€åˆ—)
        query_img, _ = raw_dataset[q_idx]
        axes[row, 0].imshow(query_img)
        axes[row, 0].set_title(f"QUERY\n{q_title}", color="darkred", fontsize=12, fontweight='bold')
        axes[row, 0].axis('off')
        
        # ç»˜åˆ¶ Matches (åäº”åˆ—)
        for col in range(1, 6):
            idx = topk_indices[col].item()
            score = topk_scores[col].item()
            match_img, _ = raw_dataset[idx]
            
            axes[row, col].imshow(match_img)
            axes[row, col].set_title(f"Sim: {score:.3f}", fontsize=10)
            axes[row, col].axis('off')

    # æ·»åŠ æ€»æ ‡é¢˜
    plt.suptitle(f"LeJEPA Contrastive Search Demo (Model: {latest_ckpt.name})", fontsize=16, y=0.98)
    
    save_path = "demo_contrastive_result.png"
    plt.savefig(save_path, dpi=200, bbox_inches='tight')
    print(f"âœ… å¯¹æ¯”æ¼”ç¤ºå›¾å·²ä¿å­˜: {save_path}")
    print("   (è¯·åœ¨ Windows ä¸­æ‰“å¼€æŸ¥çœ‹ï¼ŒéªŒè¯ä¸åŒè¡Œçš„é£æ ¼æ˜¯å¦æˆªç„¶ä¸åŒ)")

if __name__ == "__main__":
    run_contrastive_search()
